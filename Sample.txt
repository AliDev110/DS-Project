********This file is for testing the project********

For instance, consider the text “A b ????”. Using the table above, we can see that this is
represented as the following sequence of bytes: “65 32 98 32 63 63 63 63”. Note that the space
counts as a character, and its value in the ASCII encoding is 32.If we write out the binary string
for each character according to the table above and concatenate them together, we
get “0100000100100000011000100010000000111111001111110011111100111111”. Storing
our original string with the ASCII encoding requires 8*8 = 64 bits. There are 8 characters in the
text “A b ????” and each character is represented by a byte that is 8 bits long.
Now, imagine if we weren’t forced to use eight bits for every character, and we could instead use
the binary encoding “? = 0, [space] = 10, A = 110, b = 111”. Then our string “A b ????” would
become “11010111100000”. This is only 14 bits, significantly smaller than the 64 bits that ASCII
requires. Also notice that none of these codes are a prefix of any others, so there is no ambiguity
when decoding. Here, we compressed our string by finding a different encoding for the characters
that minimized the number of bits we needed to use.

One of the most important lossless data compression algorithms is called Huffman coding. A
Huffman code is defined by a tree, whose leaves are the symbols in the alphabet. For example,
the tree